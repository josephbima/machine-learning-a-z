# Pros and Cons of Regression Models

## Linear Regression

#### Pros

``` 
    1. Works on any size of dataset
    2. Gives a clear relationship about the relevance of features
    
```

#### Cons

``` 
  1. The 5 linear regression assumptions 
```

## Polynomial Regression

#### Pros

``` 
    1. Works on any size of dataset
    2. Works very well on non-linear problems
```

#### Cons

``` 
  1. Need to chose the right polynomial degree
```

## Support Vector Regression (SVR)

#### Pros

``` 
    1. Easily adaptable
    2. Works very well on non-linear problems
    3. Not biased by outliers
```

#### Cons

``` 
  1. Need to apply feature scaling
```

## Decision Tree Regression

#### Pros

``` 
    1. Works on linear and non-linear problems
    2. No need for feature scaling
    3. Interpertability
```

#### Cons

``` 
  1. Easy to overfit
  2. Poor result on smaller database
```
## Random Forrest Regression

#### Pros

``` 
    1. Powerful and accurate
    2. No need for feature scaling
    3. Good performance on many problems
```

#### Cons

``` 
  1. Easy to overfit
  2. Poor result on smaller database
  3. No interpertability
  3. Need to choose the right amount of trees
```
